{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mouse(event,x,y,flags, param):\n",
    "  global oldx, oldy\n",
    "\n",
    "  if event == cv2.EVENT_LBUTTONDOWN:\n",
    "    oldx, oldy = x,y\n",
    "\n",
    "    elif event ==cv2.EVENT_MOUSEMOVE:\n",
    "      if flags ==cv2.EVENT_FLAG_LBUTTON:\n",
    "        cv2.line(img, (oldx,oldy),(x,y), (0,0,255),\n",
    "                 5, cv2.LINE_AA)\n",
    "        cv2.imshow('image', img)\n",
    "        oldx, oldy = x,y\n",
    "\n",
    "\n",
    "\n",
    "img = np.ones((500,700,3),np.uint8)*255\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image', call_mouse, img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fig2/puppy.bmp')\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "  key = cv2.waitKey()\n",
    "\n",
    "  if key == 27 or key == ord('q'):\n",
    "    break\n",
    "\n",
    "  elif key == ord('i'):\n",
    "    img= 255 -img\n",
    "    cv2.imshow('image', img)\n",
    "\n",
    "  elif key == ord('e'):\n",
    "    img = cv2.Canny(img, 100,150)\n",
    "    cv2.imshow('image',img)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "f_flag = False\n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    print('frame read failed')\n",
    "    continue\n",
    "  \n",
    "  if f_flag:\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "  cv2.imshow('image', frame)\n",
    "\n",
    "  key = cv2.waitKey(30)\n",
    "  if key ==27:\n",
    "    break\n",
    "  elif key == ord('f'):\n",
    "    f_flag = not f_flag\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (미완)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "f_flag = False\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FRAME_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*DIVX)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  if not ret:\n",
    "    print('frame read failed')\n",
    "    continue\n",
    "  \n",
    "  if f_flag:\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "  cv2.imshow('image', frame)\n",
    "  out.write(frame)\n",
    "\n",
    "\n",
    "\n",
    "  key = cv2.waitKey(30)\n",
    "  if key ==27:\n",
    "    break\n",
    "  elif key == ord('f'):\n",
    "    f_flag = not f_flag\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.ones((800,1200,3),np.uint8)*255\n",
    "\n",
    "cv2.line(img, (100,100), (300,100), (0,0,255), 10, cv2.LINE_AA)\n",
    "cv2.arrowedLine(img, (100,200), (300,300), (255, 0,0), 10, cv2.LINE_AA)\n",
    "cv2.rectangle(img, (100,400), (300,500), (0,255,0), -1)\n",
    "cv2.circle(img, (500,300), 100, (0,0,255), 10, cv2.LINE_AA)\n",
    "cv2.putText(img, 'Hello OpenCV', (500,500), cv2.FONT_HERSHEY_COMPLEX,\n",
    "            3,(0,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_trackbar(pos):\n",
    "  img[:] = img1*pos\n",
    "  cv2.imshow('image', img)\n",
    "\n",
    "\n",
    "\n",
    "img = np.ones((400,600,3), np.uint8)\n",
    "img1 =img.copy()\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.createTrackbar('LEVEL', 'image', 150,255,call_trackbar)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.memmap import uint8\n",
    "#영상띄울때 트랙바 콜백 과제\n",
    "def call_trackbar(pos):\n",
    "  img[:] = img1*((pos/255.).astype(np.uint8)\n",
    "\n",
    "  cv2.imshow('image', img)\n",
    "\n",
    "\n",
    "img = cv2.imread('./fig2/puppy.bmp',0)\n",
    "img1 =img.copy()\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.createTrackbar('LEVEL', 'image', 0,255, call_trackbar)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#여기까지가 2장 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#여기서부터 3장 내용(영상의 화소점 처리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fig_3/lenna.bmp', 0 )\n",
    "\n",
    "img1 = img +100\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('image+100', img1) #clipping을 해줘야 하는 상태\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./fig_3/lenna.bmp', 0 )\n",
    "\n",
    "# img1 = np.clip(img+100., 0, 255).astype(np.uint8) #타입:플롯 ->int로 타입바꿔줘야함./ 클리핑 해준상태\n",
    "\n",
    "img2 = cv2.add(img, 100)\n",
    "\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.imshow('image+100', img1) #clipping을 해준 상태\n",
    "cv2.imshow('cv2.add', img2)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영상 컬러로 불러오기\n",
    "src = cv2.imread('./fig_3/lenna.bmp')\n",
    "\n",
    "dst = cv2.add(src, (100,100,100, 0)) #알파채널인 0을 포함시킨다.\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#프레임처리 (영상끼리 더하고 빼는 과정)\n",
    "src1 = cv2.imread('./fig_3/lenna256.bmp', 0 ) #채널을 흑백으로 둬야함.\n",
    "src2 = np.zeros((256,256), np.uint8)\n",
    "cv2.circle(src2, (128,128), 100, 200,-1)\n",
    "cv2.circle(src2, (128,128), 50, 50,-1)\n",
    "\n",
    "\n",
    "#클립핑은 자동으로 해준다. , 만약에 dtype이 다르면 바꿔주어야함.\n",
    "dst1 = cv2.add(src1, sr2)\n",
    "dst2 = cv2.addWeighted(src1, 0.5, src2, 0.5, 0) # 알파*I + ((1-알파)=베타) +감마(얼마나 올려줄지)\n",
    "dst3 = cv2.subtract(src1, src2)\n",
    "dst4 = cv2.absdiff(src1, src2)  #마이너스 값을 절댓값씌워서 눈에 보이게끔 만들어줌.\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('src1', src1)\n",
    "cv2.imshow('src2', src2)\n",
    "\n",
    "cv2.imshow('dst1', dst1)\n",
    "cv2.imshow('dst2', dst2)\n",
    "cv2.imshow('dst3', dst3)\n",
    "cv2.imshow('dst4', dst4)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bit연산자\n",
    "\n",
    "src1 = np.zeros((256, 256), np.uint8)\n",
    "src2 = np.zeros((256, 256), np.uint8)\n",
    "cv2.rectangle(src1, (10,10), (127, 250),255, -1)\n",
    "cv2.circle(src2, (128,128), 100,127, -1)\n",
    "\n",
    "bit_and = cv2.bitwise_and(src1, src2)\n",
    "bit_or = cv2.bitwise_or(src1, src2)\n",
    "bit_xor = cv2.bitwise_xor(src1, src2)\n",
    "not_src1 = cv2.bitwise_not(src1)\n",
    "\n",
    "# cv2.imshow('src1', src1)\n",
    "# cv2.imshow('src2', src2)\n",
    "\n",
    "\n",
    "plt.subplot(231), plt.imshow(src1, 'gray'), plt.axis('off'), plt.title(\"src1\")\n",
    "plt.subplot(232), plt.imshow(src2, 'gray'), plt.axis('off'), plt.title(\"src2\")\n",
    "plt.subplot(233), plt.imshow(bit_and, 'gray'), plt.axis('off'), plt.title(\"bit_and\")\n",
    "plt.subplot(234), plt.imshow(bit_or, 'gray'), plt.axis('off'), plt.title(\"bit_or\")\n",
    "plt.subplot(235), plt.imshow(bit_xor, 'gray'), plt.axis('off'), plt.title(\"bit_xor\")\n",
    "plt.subplot(236), plt.imshow(not_src1, 'gray'), plt.axis('off'), plt.title(\"not_src1\")\n",
    "plt.show()\n",
    "\n",
    "#코드 다시 확인해볼것.\n",
    "\n",
    "cv2.imshow('src1', src1)\n",
    "cv2.imshow('src2', src2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 컬러의 특성들 확인\n",
    "src = cv2.imread('./fig_3/flowers.jpg', cv2.IMREAD_COLOR)\n",
    "# print(scr.shape)\n",
    "\n",
    "\n",
    "src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "b, g, r = cv2.split(src)\n",
    "h, s, v = cv2.split(src_hsv)\n",
    "\n",
    "# dst_merge = cv2.merge((b,g,r))\n",
    "# dst_merge = cv2.merge((r,g,b)) #bgr이 뒤집혀서 나오는 상태\n",
    "\n",
    "# b = src[:,:,0]\n",
    "# g = src[:,:,1]\n",
    "# r = src[:,:,-1]\n",
    "\n",
    "#rgb 공간에서 확인\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('b', b)\n",
    "cv2.imshow('g', g) #탁도가 높은 상태\n",
    "cv2.imshow('r', r)\n",
    "# cv2.imshow('dst_merge', dst_merge)  #합친것 확인\n",
    "\n",
    "#hvs 공간에서 확인(다루기 편해짐)\n",
    "cv2.imshow('h', h)\n",
    "cv2.imshow('v', v)\n",
    "cv2.imshow('s', s)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영상의 히스토그램 확인\n",
    "\n",
    "src = cv2.imread('./fig_3/lenna.bmp', 0) #흑백인경우\n",
    "\n",
    "hist = cv2.calcHist([src], [0], None, [256], [0, 256]) #리스트 형식으로 넣어줘야함.\n",
    "\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.plot(hist)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영상의 히스토그램 확인\n",
    "\n",
    "src = cv2.imread('./fig_3/lenna.bmp', 1) #컬러인경우\n",
    "\n",
    "hist_b = cv2.calcHist([src], [0], None, [256], [0, 256]) #리스트 형식으로 넣어줘야함.\n",
    "hist_g = cv2.calcHist([src], [1], None, [256], [0, 256]) #리스트 형식으로 넣어줘야함.\n",
    "hist_r = cv2.calcHist([src], [2], None, [256], [0, 256]) #리스트 형식으로 넣어줘야함.\n",
    "\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.plot(hist_b)\n",
    "plt.plot(hist_g)\n",
    "plt.plot(hist_r)\n",
    "plt.show\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
