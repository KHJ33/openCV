{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a540249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac81cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_style = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=4, min_detection_confidence=0.5)\n",
    "\n",
    "files = ['./fig/hand.jpg']\n",
    "\n",
    "img = cv2.flip(cv2.imread(files[0], 1), 1)\n",
    "img_bgr = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "annotated_img = img.copy()\n",
    "\n",
    "result = hands.process(img_bgr)\n",
    "\n",
    "# cv2.imshow('image', img_bgr)\n",
    "\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('handness', result.multi_handedness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab601519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('handness', result.multi_handedness[0].classification[0].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37c17e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print('landmark', result.multi_hand_landmarks[0].landmark)\n",
    "print('fingers:', result.multi_hand_landmarks[0].landmark[8])\n",
    "print('landmark', result.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing.draw_landmarks(annotated_img, \n",
    "                          landmark_list=result.multi_hand_landmarks[0], \n",
    "                          connections = mp_hands.HAND_CONNECTIONS,\n",
    "                          landmark_drawing_spec=mp_drawing_style.get_default_hand_landmarks_style(),\n",
    "                          connection_drawing_spec=mp_drawing_style.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1286db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', annotated_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82978c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                          mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                                          mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df179a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e82af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('./fig/Son.mp4')\n",
    "with mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "getCou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b324ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "        continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS, \n",
    "                                          mp_drawing_styles.get_default_hand_landmarks_style(), \n",
    "                                          mp_drawing_styles.get_default_hand_connections_style())\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7524c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8d8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1803678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'handtrackingmodule.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691cad61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'handtrackingmodule'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhandtrackingmodule\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhtm\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'handtrackingmodule'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import handtrackingmodule as htm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "overlayList=[]#list to store all the images\n",
    "\n",
    "brushThickness = 25\n",
    "eraserThickness = 100\n",
    "drawColor=(255,0,255)#setting purple color\n",
    "\n",
    "xp, yp = 0, 0\n",
    "imgCanvas = np.zeros((720, 1280, 3), np.uint8)# defining canvas\n",
    "\n",
    "#images in header folder\n",
    "folderPath='./AI-Virtual-Paint-main/Header/'\n",
    "myList=os.listdir(folderPath)#getting all the images used in code\n",
    "#print(myList)\n",
    "for imPath in myList:#reading all the images from the folder\n",
    "    image=cv2.imread(f'{folderPath}/{imPath}')\n",
    "    overlayList.append(image)#inserting images one by one in the overlayList\n",
    "header=overlayList[0]#storing 1st image \n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,1280)#width\n",
    "cap.set(4,720)#height\n",
    "\n",
    "detector = htm.handDetector(detectionCon=0.50,maxHands=1)#making object\n",
    "\n",
    "while True:\n",
    "\n",
    "    # 1. Import image\n",
    "    success, img = cap.read()\n",
    "    img=cv2.flip(img,1)#for neglecting mirror inversion\n",
    "    \n",
    "    # 2. Find Hand Landmarks\n",
    "    img = detector.findHands(img)#using functions fo connecting landmarks\n",
    "    lmList,bbox = detector.findPosition(img, draw=False)#using function to find specific landmark position,draw false means no circles on landmarks\n",
    "    \n",
    "    if len(lmList)!=0:\n",
    "        #print(lmList)\n",
    "        x1, y1 = lmList[8][1],lmList[8][2]# tip of index finger\n",
    "        x2, y2 = lmList[12][1],lmList[12][2]# tip of middle finger\n",
    "        \n",
    "        # 3. Check which fingers are up\n",
    "        fingers = detector.fingersUp()\n",
    "        #print(fingers)\n",
    "\n",
    "        # 4. If Selection Mode - Two finger are up\n",
    "        if fingers[1] and fingers[2]:\n",
    "            xp,yp=0,0\n",
    "            #print(\"Selection Mode\")\n",
    "            #checking for click\n",
    "            if y1 < 125:\n",
    "                if 250 < x1 < 450:#if i m clicking at purple brush\n",
    "                    header = overlayList[0]\n",
    "                    drawColor = (255, 0, 255)\n",
    "                elif 550 < x1 < 750:#if i m clicking at blue brush\n",
    "                    header = overlayList[1]\n",
    "                    drawColor = (255, 0, 0)\n",
    "                elif 800 < x1 < 950:#if i m clicking at green brush\n",
    "                    header = overlayList[2]\n",
    "                    drawColor = (0, 255, 0)\n",
    "                elif 1050 < x1 < 1200:#if i m clicking at eraser\n",
    "                    header = overlayList[3]\n",
    "                    drawColor = (0, 0, 0)\n",
    "            cv2.rectangle(img, (x1, y1 - 25), (x2, y2 + 25), drawColor, cv2.FILLED)#selection mode is represented as rectangle\n",
    "\n",
    "\n",
    "        # 5. If Drawing Mode - Index finger is up\n",
    "        if fingers[1] and fingers[2] == False:\n",
    "            cv2.circle(img, (x1, y1), 15, drawColor, cv2.FILLED)#drawing mode is represented as circle\n",
    "            #print(\"Drawing Mode\")\n",
    "            if xp == 0 and yp == 0:#initially xp and yp will be at 0,0 so it will draw a line from 0,0 to whichever point our tip is at\n",
    "                xp, yp = x1, y1 # so to avoid that we set xp=x1 and yp=y1\n",
    "            #till now we are creating our drawing but it gets removed as everytime our frames are updating so we have to define our canvas where we can draw and show also\n",
    "            \n",
    "            #eraser\n",
    "            if drawColor == (0, 0, 0):\n",
    "                cv2.line(img, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
    "                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, eraserThickness)\n",
    "            else:\n",
    "                cv2.line(img, (xp, yp), (x1, y1), drawColor, brushThickness)#gonna draw lines from previous coodinates to new positions \n",
    "                cv2.line(imgCanvas, (xp, yp), (x1, y1), drawColor, brushThickness)\n",
    "            xp,yp=x1,y1 # giving values to xp,yp everytime \n",
    "           \n",
    "           #merging two windows into one imgcanvas and img\n",
    "    \n",
    "    # 1 converting img to gray\n",
    "    imgGray = cv2.cvtColor(imgCanvas, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2 converting into binary image and thn inverting\n",
    "    _, imgInv = cv2.threshold(imgGray, 50, 255, cv2.THRESH_BINARY_INV)#on canvas all the region in which we drew is black and where it is black it is cosidered as white,it will create a mask\n",
    "    \n",
    "    imgInv = cv2.cvtColor(imgInv,cv2.COLOR_GRAY2BGR)#converting again to gray bcoz we have to add in a RGB image i.e img\n",
    "    \n",
    "    #add original img with imgInv ,by doing this we get our drawing only in black color\n",
    "    img = cv2.bitwise_and(img,imgInv)\n",
    "    \n",
    "    #add img and imgcanvas,by doing this we get colors on img\n",
    "    img = cv2.bitwise_or(img,imgCanvas)\n",
    "\n",
    "\n",
    "    #setting the header image\n",
    "    img[0:125,0:1280]=header# on our frame we are setting our JPG image acc to H,W of jpg images\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    #cv2.imshow(\"Canvas\", imgCanvas)\n",
    "    #cv2.imshow(\"Inv\", imgInv)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a7bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "969c52dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your current tool set to :  draw\n",
      "your current tool set to :  draw\n"
     ]
    }
   ],
   "source": [
    "#contants\n",
    "ml = 150\n",
    "max_x, max_y = 250+ml, 50\n",
    "curr_tool = \"select tool\"\n",
    "time_init = True\n",
    "rad = 40\n",
    "var_inits = False\n",
    "thick = 2\n",
    "prevx, prevy = 0,0\n",
    "\n",
    "#get tools function\n",
    "def getTool(x):\n",
    "    if x < 50 + ml:\n",
    "        return \"line\"\n",
    "    elif x<100 + ml:\n",
    "        return \"rectangle\"\n",
    "    elif x < 150 + ml:\n",
    "        return\"draw\"\n",
    "    elif x<200 + ml:\n",
    "        return \"circle\"\n",
    "    else:\n",
    "        return \"erase\"\n",
    "\n",
    "def index_raised(yi, y9):\n",
    "    if (y9 - yi) > 40:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# mediapipe handtracking 설정\n",
    "hands = mp.solutions.hands\n",
    "hand_landmark = hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=2)\n",
    "draw = mp.solutions.drawing_utils\n",
    "\n",
    "# drawing tools\n",
    "tools = cv2.imread(\"tools.png\")\n",
    "tools = tools.astype('uint8')\n",
    "\n",
    "mask = np.ones((480, 640))*255\n",
    "mask = mask.astype('uint8')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frm = cap.read()\n",
    "    frm = cv2.flip(frm, 1)\n",
    "    rgb = cv2.cvtColor(frm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    op = hand_landmark.process(rgb)\n",
    "\n",
    "    if op.multi_hand_landmarks:\n",
    "        for i in op.multi_hand_landmarks:\n",
    "            draw.draw_landmarks(frm, i, hands.HAND_CONNECTIONS)\n",
    "            x, y = int(i.landmark[8].x*640), int(i.landmark[8].y*480)\n",
    "\n",
    "            if x < max_x and y < max_y and x > ml:\n",
    "                if time_init:\n",
    "                    ctime = time.time()\n",
    "                    time_init = False\n",
    "                ptime = time.time()\n",
    "\n",
    "                cv2.circle(frm, (x, y), rad, (0,255,255), 2)\n",
    "                rad -= 1\n",
    "\n",
    "                if (ptime - ctime) > 0.8:\n",
    "                    curr_tool = getTool(x)\n",
    "                    print(\"your current tool set to : \", curr_tool)\n",
    "                    time_init = True\n",
    "                    rad = 40\n",
    "            else:\n",
    "                time_init = True\n",
    "                rad = 40\n",
    "\n",
    "            if curr_tool == \"draw\":\n",
    "                xi, yi = int(i.landmark[12].x*640), int(i.landmark[12].y*480)\n",
    "                y9  = int(i.landmark[9].y*480)\n",
    "\n",
    "                if index_raised(yi, y9):\n",
    "                    cv2.line(mask, (prevx, prevy), (x, y), 0, thick)\n",
    "                    prevx, prevy = x, y\n",
    "                else:\n",
    "                    prevx = x\n",
    "                    prevy = y\n",
    "            elif curr_tool == \"line\":\n",
    "                xi, yi = int(i.landmark[12].x*640), int(i.landmark[12].y*480)\n",
    "                y9  = int(i.landmark[9].y*480)\n",
    "\n",
    "                if index_raised(yi, y9):\n",
    "                    if not(var_inits):\n",
    "                        xii, yii = x, y\n",
    "                        var_inits = True\n",
    "                    cv2.line(frm, (xii, yii), (x, y), (0,152,255), thick)\n",
    "\n",
    "                else:\n",
    "                    if var_inits:\n",
    "                        cv2.line(mask, (xii, yii), (x, y), 0, thick)\n",
    "                        var_inits = False\n",
    "\n",
    "            elif curr_tool == \"rectangle\":\n",
    "                xi, yi = int(i.landmark[12].x*640), int(i.landmark[12].y*480)\n",
    "                y9  = int(i.landmark[9].y*480)\n",
    "\n",
    "                if index_raised(yi, y9):\n",
    "                    if not(var_inits):\n",
    "                        xii, yii = x, y\n",
    "                        var_inits = True\n",
    "\n",
    "                    cv2.rectangle(frm, (xii, yii), (x, y), (0,255,0), thick)\n",
    "\n",
    "                else:\n",
    "                    if var_inits:\n",
    "                        cv2.rectangle(mask, (xii, yii), (x, y), 0, thick)\n",
    "                        var_inits = False\n",
    "\n",
    "            elif curr_tool == \"circle\":\n",
    "                xi, yi = int(i.landmark[12].x*640), int(i.landmark[12].y*480)\n",
    "                y9  = int(i.landmark[9].y*480)\n",
    "\n",
    "                if index_raised(yi, y9):\n",
    "                    if not(var_inits):\n",
    "                        xii, yii = x, y\n",
    "                        var_inits = True\n",
    "\n",
    "                    cv2.circle(frm, (xii, yii), int(((xii-x)**2 + (yii-y)**2)**0.5), (255,255,0), thick)\n",
    "                else:\n",
    "                    if var_inits:\n",
    "                        cv2.circle(mask, (xii, yii), int(((xii-x)**2 + (yii-y)**2)**0.5), (0,255,0), thick)\n",
    "                        var_inits = False\n",
    "\n",
    "            elif curr_tool == \"erase\":\n",
    "                xi, yi = int(i.landmark[12].x*640), int(i.landmark[12].y*480)\n",
    "                y9  = int(i.landmark[9].y*480)\n",
    "\n",
    "                if index_raised(yi, y9):\n",
    "                    cv2.circle(frm, (x, y), 30, (0,0,0), -1)\n",
    "                    cv2.circle(mask, (x, y), 30, 255, -1)\n",
    "\n",
    "    op = cv2.bitwise_and(frm, frm, mask=mask)\n",
    "    frm[:, :, 1] = op[:, :, 1]\n",
    "    frm[:, :, 2] = op[:, :, 2]\n",
    "\n",
    "    frm[:max_y, ml:max_x] = cv2.addWeighted(tools, 0.7, frm[:max_y, ml:max_x], 0.3, 0)\n",
    "\n",
    "    cv2.putText(frm, curr_tool, (270+ml,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "    cv2.imshow(\"paint app\", frm)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec8fc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903358c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
